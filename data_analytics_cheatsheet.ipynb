{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA with Pandas Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV File\n",
    "\n",
    "df = pd.read_csv('filename.csv')\n",
    "\n",
    "# Read Excel File\n",
    "\n",
    "df = pd.read_excel('filename.xlsx')\n",
    "\n",
    "# Read from SQL Database\n",
    "\n",
    "df = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Top Rows\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Display Bottom Rows\n",
    "\n",
    "df.tail()\n",
    "\n",
    "# Display Data Types\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "# Summary Statistics\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# Display Index, Columns, and Data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Missing Values\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "# Fill Missin Values\n",
    "\n",
    "df.fillna(value)\n",
    "\n",
    "# Drop Missing Values\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "# Rename Columns\n",
    "\n",
    "df.rename(columns = {'old_name': 'new_name'})\n",
    "\n",
    "# Drop Columns\n",
    "\n",
    "df.drop(columns=['column_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "\n",
    "df['column'].apply(lambda x: function(x))\n",
    "\n",
    "# Group By and Aggregate \n",
    "\n",
    "df.groupby('column').agg({'column': 'sum' })\n",
    "\n",
    "# Pivot Tables\n",
    "\n",
    "df.pivot_table(index='column1', values='column2',\n",
    "aggfunc='mean')\n",
    "\n",
    "# Merge DataFrames\n",
    "\n",
    "pd.merge(df1, df2, on='column')\n",
    "\n",
    "# Concatenate DataFrames\n",
    "\n",
    "pd.concat([df1, df2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Visualization Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "df['column'].hist()\n",
    "\n",
    "# Boxplot \n",
    "\n",
    "df.boxplot(column=['column1', 'column2'])\n",
    "\n",
    "# Scatter Plot\n",
    "\n",
    "df.plot.scatter(x='col1', y='col2')\n",
    "\n",
    "# Line Plot\n",
    "\n",
    "df.plot.line()\n",
    "\n",
    "# Bar Chart\n",
    "\n",
    "df['column'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "df.corr()\n",
    "\n",
    "# Covariance Matrix\n",
    "\n",
    "df.cov()\n",
    "\n",
    "# Value Counts \n",
    "\n",
    "df['column'].value_counts()\n",
    "\n",
    "# Unique Values in Column\n",
    "\n",
    "df['column'].unique()\n",
    "\n",
    "# Number of Unique Values\n",
    "\n",
    "df['column'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Indexing and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Column\n",
    "\n",
    "df['column']\n",
    "\n",
    "# Select Multiple Columns\n",
    "\n",
    "df[['col1', 'co12']]\n",
    "\n",
    "# Select Rows by Position\n",
    "\n",
    "df.iloc[0:5]\n",
    "\n",
    "# Select Rows by Label\n",
    "\n",
    "df.loc[0:5]\n",
    "\n",
    "# Conditional Selection\n",
    "\n",
    "df[df['column'] > value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Data Formatting and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data Types\n",
    "\n",
    "df['column'].astype('type')\n",
    "\n",
    "# String Operations \n",
    "\n",
    "df['column'].str.lower()\n",
    "\n",
    "# Datetime Conversion \n",
    "\n",
    "pd.to_datetime(df['column'])\n",
    "\n",
    "# Setting Index \n",
    "\n",
    "df.set_index('column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Advanced Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda Functions \n",
    " \n",
    "df.apply(lambda x: x + 1)\n",
    "\n",
    "# Pivot Longer/Wider Format \n",
    " \n",
    "df.melt(id_vars=['col1'])\n",
    "\n",
    "# Stack/Unstack \n",
    " \n",
    "df.stack(), df.unstack()\n",
    "\n",
    "# Cross Tabulations \n",
    "\n",
    "pd.crosstab(df['col1'], df['col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Handling Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Datetime Index\n",
    "\n",
    "df.set_index(pd.to_datetime(df['date']))\n",
    "\n",
    "# Resampling Data\n",
    "\n",
    "df.resample('M').mean()\n",
    "\n",
    "# Rolling Window Operations\n",
    "\n",
    "df.rolling(window=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. File Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "\n",
    "df.to_csv('filename.csv')\n",
    "\n",
    "# Write to Excel\n",
    "\n",
    "df.to_excel('filename.xlsx')\n",
    "\n",
    "# Write to SQL Database\n",
    "\n",
    "df.to_sql('table_name', connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Data Exploration Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile Report (with pandas-profiling)\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "ProfileReport(df)\n",
    "\n",
    "# Pairplot (with seaborn)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pairplot(df)\n",
    "\n",
    "# Heatmap for correlation (with seaborn)\n",
    "\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Advance Data Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Function\n",
    "\n",
    "df.query('column > value')\n",
    "\n",
    "# Filtering with isin\n",
    "\n",
    "df[df['column'].isin([value1, value2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Memory Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing Memory Usage\n",
    "\n",
    "df.memory_usage(deep=True)\n",
    "\n",
    "# Change Data Types to Save Memory\n",
    "\n",
    "df['column'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Multi-Index Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating MultiIndex\n",
    "\n",
    "df.set_index(['col1', 'col2'])\n",
    "\n",
    "# Slicing on MultiIndex\n",
    "\n",
    "df.loc[(slice('index1_start', 'index1_end'), slice('index2_start', 'index2_end'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Data Merging Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer Join \n",
    "\n",
    "pd.merge(df1, df2, on='column', how='outer')\n",
    "\n",
    "# Inner Join \n",
    "\n",
    "pd.merge(df1, df2, on='column', how='inner')\n",
    "\n",
    "# Left Join\n",
    "\n",
    "pd.merge(df1, df2, on='column', how='left')\n",
    "\n",
    "# Right Join \n",
    "\n",
    "pd.merge(df1, df2, on='column', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Duplicates\n",
    "\n",
    "df.duplicated()\n",
    "\n",
    "# Removing Duplicates \n",
    "\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Custom Operation with Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Apply Functions\n",
    "\n",
    "df.apply(lambda row:custom_func(row['col1'], row['col2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Handling Large Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking Large Files\n",
    "\n",
    "pd.read_csv('large_file.csv', chunksize=1000)\n",
    "\n",
    "# Iterating Through Data Chunks\n",
    "\n",
    "for chunk in pd.read_csv('file.csv', chunksize=500): process(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Integration with Matplotlib for Custom Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Plotting\n",
    "\n",
    "import matplotlib.pyplot as plt; df.plot();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Specialized Data Types Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Categorical Data\n",
    "\n",
    "df['column'].astype('category')\n",
    "\n",
    "# Dealing with Sparse Data \n",
    "    \n",
    "pd.arrays.SparseArray(df['column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Visualization Enchancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize Plot Style\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Histogram with Bins Specification \n",
    "    \n",
    "df['column'].hist(bins=20)\n",
    "\n",
    "# Boxplot Grouped by Category \n",
    "\n",
    "df.boxplot(column='num_column', by='cat_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Advanced Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Multiple Columns\n",
    "\n",
    "df.groupby(['col1', 'col2']).mean()\n",
    "\n",
    "# Aggregate with Multiple Functions \n",
    "\n",
    "df.groupby('col').agg(['mean', 'sum'])\n",
    "\n",
    "# Transform Function \n",
    "\n",
    "df.groupby('col').transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Time Series Specific Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Based Grouping\n",
    "\n",
    "df.groupby(pd.Grouper(key='date_col', freq='M')).sum()\n",
    "\n",
    "# Shifting Series for Lag Analysis \n",
    "\n",
    "df['column'].shift(1)\n",
    "\n",
    "# Resample Time Series Data \n",
    "\n",
    "df.resample('M', on='date_col').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Text Data Specific Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Contains\n",
    "\n",
    "df[df['column'].str.contains('substring')]\n",
    "\n",
    "# String Split \n",
    "\n",
    "df['column'].str.split(' ', expand=True)\n",
    "\n",
    "# Regular Expression Extraction \n",
    "\n",
    "df['column'].str.extract(r'(regex)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Data Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization \n",
    "\n",
    "(df['column'] - df['column'].min()) / (df ['column'].max() - df ['column'].min())\n",
    "\n",
    "# Z-Score Standardization \n",
    "\n",
    "(df['column'] - df['column'].mean()) / df['column']. std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Working with JSON and XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON\n",
    "\n",
    "df = pd.read_json('filename.json')\n",
    "\n",
    "# Reading XML\n",
    "\n",
    "df = pd.read_xml('filename.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. Advanced File Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV with Specific Delimeter\n",
    "\n",
    "df = pd.read_csv('filename.csv', delimitter=';')\n",
    "\n",
    "# Writing to JSON\n",
    "\n",
    "df.to_json('filename.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate Missing Values\n",
    "\n",
    "df['column'].interpolate()\n",
    "\n",
    "# Forward Fill Missing Values \n",
    "\n",
    "df['column'].ffill()\n",
    "\n",
    "# Backward Fill Missing Values \n",
    "\n",
    "df['column'].bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. Data Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide to Long Format\n",
    "\n",
    "pd.wide_to_long(df, ['col'], i='id_col', j='year')\n",
    "\n",
    "# Long to Wide Format \n",
    "\n",
    "df.pivot(index='id_col', columns='year', values='col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31. Categorical Data Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Column to Categorical \n",
    "\n",
    "df['column'] = df['column'].astype('category')\n",
    "\n",
    "# Order Categories \n",
    "\n",
    "df['column'].cat.set_categories(['cat1', 'cat2'], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Advanced Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index\n",
    "\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "# Set Multiple Indexes\n",
    "\n",
    "df.set_index(['col1', 'col2'])\n",
    "\n",
    "# MultiIndex Slicing\n",
    "\n",
    "df.xs(key='value', level='level_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Efficient Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of eval() for Efficient Operations\n",
    "\n",
    "df.eval('coll + col2')\n",
    "\n",
    "# Query Method for Filtering\n",
    "\n",
    "df.query('col1 < col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. Integration with SciPy and StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression (with statsmodels)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "sm.OLS(y, X).fit()\n",
    "\n",
    "# Kurtosis and Skewness (with SciPy)\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "kurtosis(df['column']), skew(df['column'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Analytics_Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
